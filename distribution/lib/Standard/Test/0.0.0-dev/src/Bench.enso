from Standard.Base import all
import Standard.Base.Errors.Illegal_Argument.Illegal_Argument
import Standard.Base.Errors.Unimplemented.Unimplemented
import Standard.Base.Runtime.Debug

## Configuration for a measurement phase or a warmup phase of a benchmark.
type Phase_Conf
    ## The minimal number of seconds for which the phase should run.
    Secs (secs:Integer)
    ## Number of iterations of the phase.
    Iters (iters:Integer)

    iterations : Integer|Nothing
    iterations self = case self of
        Phase_Conf.Secs _ -> Nothing
        Phase_Conf.Iters iters -> iters

    seconds : Integer|Nothing
    seconds self = case self of
        Phase_Conf.Secs secs -> secs
        Phase_Conf.Iters _ -> Nothing

    to_text self = case self of
        Phase_Conf.Secs secs -> secs.to_text + " seconds"
        Phase_Conf.Iters iters -> iters.to_text + " iterations"

    ## Validates the config and throws a Panic if it is invalid.
    validate : Nothing
    validate self = case self of
        Phase_Conf.Secs secs ->
            if secs < 0 then Panic.throw (Illegal_Argument.Error "Seconds must be positive")
        Phase_Conf.Iters iters ->
            if iters < 0 then Panic.throw (Illegal_Argument.Error "Iterations must be positive")


type Default_Setup
    setup : (Any|Nothing)
    setup = Nothing


type Default_Teardown
    teardown : (Any|Nothing) -> Nothing
    teardown _ = Nothing


## The benchmark options for a `Bench_Group`. These options roughly corresponds
   to the options defined in the JMH benchmarking library. See the JMH
   documentation for more details:
   https://javadoc.io/doc/org.openjdk.jmh/jmh-core/latest/org/openjdk/jmh/annotations/package-summary.html

   ! Setup and teardown configuration
     The `setup` and `teardown` are optional methods are called before starting
     a single benchmark from `Bench_Spec` and after finishing a single benchmark
     from `Bench_Spec` respectively. This frequency of calling `setup` and
     `teardown` methods corresponds to `Level.Trial` in JMH - https://javadoc.io/doc/org.openjdk.jmh/jmh-core/latest/org/openjdk/jmh/annotations/Level.html#Trial
     It is not possible to set a different frequency.

     To provide a custom implementation of the `setup` method, you need to pass
     a type that contains a single static method called `setup` that takes no
     arguments and returns any object that will be passed as input arguments to
     the benchmark.

     To provide a custom implementation of the `teardown` method, you need to
     pass a type that contains a single static method called `teardown` that
     takes a single argument and returns `Nothing`.

     Setup can be specified without Teardown, but Teardown cannot be specified
     without Setup.

     See the `Default_Setup` and `Default_Teardown` prototypes.

     Note that the providing setup or teardown behavior as static methods in
     types allows for delaying the execution of the setup and teardown code until
     the benchmark is actually run.
type Bench_Options
    ## PRIVATE
    Impl (warmup:Phase_Conf) (measure:Phase_Conf) (setup:Any) (teardown:Any)

    ## Sets the length of the warmup phase.
    set_warmup : Phase_Conf -> Bench_Options
    set_warmup self warm = Bench_Options.Impl warm self.measure self.setup self.teardown

    ## Sets the length the measurement phase.
    set_measure : Phase_Conf -> Bench_Options
    set_measure self meas = Bench_Options.Impl self.warmup meas self.setup self.teardown

    ## Sets the setup hook that is called before every benchmark invocation.

       Arguments:
       - setup: A type that has a `setup` static method that returns an object
         that will be passed as input arguments to the benchmark.
    set_setup : Any -> Bench_Options
    set_setup self setup = Bench_Options.Impl self.warmup self.measure setup self.teardown

    ## Sets the teardown hook that is called after every benchmark invocation.

       Arguments:
       - teardown: A type that has a `teardown` static method that takes a single
         argument and returns `Nothing`. It will be called after every benchmark
         invocation, with the argument being the object returned by the `setup`
         method.
    set_teardown : Any -> Bench_Options
    set_teardown self teardown = Bench_Options.Impl self.warmup self.measure self.setup teardown

    to_text self = "[warmup={" + self.warmup.to_text + "}, measurement={" + self.measure.to_text + "}, setup=" + self.setup.to_text + ", teardown=" + self.teardown.to_text + "]"

    ## Validates the config and throws a Panic if it is invalid.
    validate : Nothing
    validate self =
        self.warmup.validate
        self.measure.validate
        case (Meta.get_type_methods (Meta.type_of self.setup)).contains "setup" of
            False -> Panic.throw (Illegal_Argument.Error "setup field is not a type with a method called `setup`")
            True -> Nothing
        case (Meta.get_type_methods (Meta.type_of self.teardown)).contains "teardown" of
            False -> Panic.throw (Illegal_Argument.Error "teardown field is not a type with a method called `teardown`")
            True -> Nothing
        case (self.setup == Default_Setup && self.teardown != Default_Teardown) of
            True -> Panic.throw (Illegal_Argument.Error "Teardown cannot be specified without setup")
            False -> Nothing


type Bench_Builder
    ## PRIVATE
    Impl builder

    group : Text -> Bench_Options -> (Group_Builder -> Any) -> Any
    group self (name:Text) (configuration:Bench_Options) fn =
        validate_name name
        configuration.validate
        b = Vector.new_builder
        fn (Group_Builder.Impl b)
        self.builder.append <| Bench.Group name configuration b.to_vector


type Group_Builder
    ## PRIVATE
    Impl builder

    ## Adds a benchmark specification to the group.

       Arguments:
       - name: The name of the benchmark. Must be a valid Java identifier.
       - benchmark: The benchmark function. Takes a single argument that is
         produced by the `setup` method of the `Bench_Options` configuration.
         The return value is ignored.
    specify : Text -> (Any -> Nothing) -> Bench
    specify self (name:Text) ~benchmark =
        validate_name name
        self.builder.append <| Bench.Spec name benchmark


type Bench
    All (groups : Vector Bench)
    Group (name:Text) (configuration:Bench_Options) (specs : Vector Bench)
    Spec (name:Text) (code : Any -> Any)

    build : (Bench_Builder -> Any) -> Bench
    build fn =
        b = Vector.new_builder
        fn (Bench_Builder.Impl b)
        Bench.All b.to_vector

    options : Bench_Options
    options = Bench_Options.Impl (Phase_Conf.Secs 3) (Phase_Conf.Secs 3) Default_Setup Default_Teardown

    fold : Any -> (Any -> Bench -> Bench -> Any) -> Any
    fold self value fn = case self of
        Bench.All groups -> groups.fold value (v-> g-> g.fold v fn)
        Bench.Group _ _ specs -> specs.fold value (v-> s-> fn v self s)
        Bench.Spec _ _ -> fn value self self

    run_main self =
        count = self.fold 0 v-> _-> _-> v+1
        IO.println <| "Found " + count.to_text + " cases to execute"

        self.fold Nothing _-> g-> s->
            conf = g.configuration
            bench_name = g.name + "." + s.name
            input_arg = conf.setup.setup
            IO.println <| "Benchmarking '" + bench_name + "' configuration: " + conf.to_text
            Bench.measure bench_name conf (s.code input_arg)
            conf.teardown.teardown input_arg

    ## Measure the amount of time it takes to execute a given computation.

       Arguments:
       - act: The action to perform.
       - label: A name for the benchmark.
       - warmup_iters: The number of warmup iterations.
       - measurement_iters: The number of measurement iterations.
       - run_gc_between_iterations: Whether to try running the garbage collector
         between iterations. Defaults to False. This is helpful when testing
         memory intensive operations, to ensure that GC runs between iterations
         and not _during_ iterations. The time taken to run the requested
         garbage collection will not be counted into the iteration time, however
         there is no guarantee that the JVM will actually accept the GC hint and
         it is still possible the JVM may run GC during an iteration. But
         setting this option to True should make it less likely for GC to
         interrupt measurements.

       > Example
         Measure a computation called "foo" with an iteration size of 2 and a number
         of iterations of 1.

             import Standard.Examples
             from Standard.Test import Bench

             example_measure =
                 Bench.measure "foo" warmup_iters=2 measurement_iters=1 Examples.get_boolean
    measure : Text -> Phase_Conf -> Phase_Conf -> Boolean -> Any -> Nothing
    measure (label:Text) (bench_opts:Bench_Options) ~act =
        dry_run = Environment.get "ENSO_BENCHMARK_TEST_DRY_RUN" "False" == "True"
        measure_start = System.nano_time

        single_call = _ ->
            x1 = System.nano_time
            Runtime.no_inline act
            x2 = System.nano_time
            x2 - x1

        run_phase (phase_name:Text) (conf:Phase_Conf) =
            phase_start = System.nano_time
            durations = case conf of
                Phase_Conf.Secs secs ->
                    stop_ns = phase_start + secs * 1000000000
                    go = durations -> cur_ns ->
                        if cur_ns  > stop_ns then durations else
                            dur = single_call Nothing
                            @Tail_Call go (durations + [dur]) (cur_ns + dur)
                    go [] phase_start
                Phase_Conf.Iters iters ->
                    go = durations -> cur_iter ->
                        if cur_iter >= iters then durations else
                            dur = single_call Nothing
                            @Tail_Call go (durations + [dur]) (cur_iter + 1)
                    go [] 0
            sum = durations.reduce (_ + _)
            run_iters = durations.length
            avg = sum / run_iters
            fmt = (avg / 1000000).format "#.###"
            phase_end = System.nano_time
            phase_duration_ms = (phase_end - phase_start) / 1000000
            IO.println <| phase_name + " duration: " + phase_duration_ms.to_text + " ms"
            IO.println <| phase_name + " iterations: " + run_iters.to_text
            IO.println <| phase_name + " avg time: " + fmt + " ms"

        empty_conf = Phase_Conf.Iters 0
        if dry_run then run_phase "dummy" empty_conf else
            warmup_durations = run_phase "Warmup" bench_opts.warmup
            measure_durations = run_phase "Measurement" bench_opts.measure
            measure_end = System.nano_time
            measure_duration_ms = (measure_end - measure_start) / 1000000
            fmt_duration_ms = measure_duration_ms.format "#.###"
            IO.println <| "Benchmark '" + label + "' finished in " + fmt_duration_ms + " ms"

## PRIVATE

   Checks whether the given name is a valid benchmark name - either group name
   or a spec name. The name should be a valid Java identifier.
   Throw a Panic error if the validation fails.
validate_name : Text -> Nothing
validate_name name =
    # Cannot start with a digit
    valid_java_identifier_regex = Regex.compile "[A-Za-z_$][a-zA-Z0-9_$]*"
    if valid_java_identifier_regex.matches name then Nothing else
        Panic.throw (Illegal_Argument.Error ("Invalid benchmark name: '" + name + "'"))
