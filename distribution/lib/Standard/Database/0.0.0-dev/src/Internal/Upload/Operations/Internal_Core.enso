private

from Standard.Base import all
import Standard.Base.Errors.Illegal_Argument.Illegal_Argument

from Standard.Table import Table

import project.Column_Description.Column_Description
import project.Connection.Connection.Connection
import project.DB_Table.DB_Table
import project.Internal.In_Transaction.In_Transaction
import project.Internal.IR.Query.Query
import project.SQL_Query.SQL_Query
from project.Errors import SQL_Error, Unsupported_Database_Operation
from project.Internal.Upload.Helpers.Argument_Checks import check_transaction_ddl_support, resolve_primary_key
from project.Internal.Upload.Helpers.Constants import default_batch_size
from project.Internal.Upload.Helpers.Error_Helpers import handle_upload_errors, internal_translate_known_upload_errors
from project.Internal.Upload.Helpers.Prepare_Structure import align_structure, validate_structure, verify_structure_hint
from project.Internal.Upload.Helpers.SQL_Helpers import make_batched_insert_template, prepare_create_table_statement

## PRIVATE
   Assumes the output context is enabled for it to work.
   Does not check if the table already exists - so if it does, it may fail with
   `SQL_Error`. The caller should perform the check for better error handling.
internal_create_table_structure connection table_name structure primary_key temporary on_problems:Problem_Behavior =
    aligned_structure = align_structure connection structure
    resolved_primary_key = resolve_primary_key aligned_structure primary_key
    validate_structure connection.base_connection.column_naming_helper aligned_structure <|
        create_table_statement = prepare_create_table_statement connection table_name aligned_structure resolved_primary_key temporary on_problems
        check_transaction_ddl_support connection
        update_result = create_table_statement.if_not_error <|
            connection.execute_update create_table_statement
        update_result.if_not_error <|
            table_name

## PRIVATE
   A helper that can upload a table from any backend to a database.
   It should be run within a transaction and wrapped in `handle_upload_errors`.

   Arguments:
   - source_table: the table to be uploaded.
     If it's a `DB_Table`, the query will be materialized as a new table.
     If it's an In Memmory `Table`, the data will be uploaded to the newly created table.
   - connection: the connection to the database.
   - table_name: the name of the table to be created.
   - primary_key: the primary key of the table to be created. Can be `Nothing` to set no key.
   - temporary: if `True`, the table will be created as temporary.
   - structure_hint: If set, it can be used to hint what types should be used for the columns of the table. Useful if the types slightly differ from the in-memory source types.
   - on_problems: the behavior to be used when reporting problems.
   - row_limit: if set, only the first `row_limit` rows will be uploaded.
internal_upload_table : DB_Table | Table -> Connection -> Text -> Nothing | Vector Text -> Boolean -> Vector Column_Description ->  Problem_Behavior -> Integer|Nothing -> DB_Table
internal_upload_table source_table connection table_name primary_key temporary structure_hint=Nothing on_problems:Problem_Behavior=..Report_Error row_limit=Nothing =
    case source_table of
        _ : Table ->
            internal_upload_in_memory_table source_table connection table_name primary_key temporary structure_hint on_problems row_limit
        _ : DB_Table ->
            internal_upload_database_table source_table connection table_name primary_key temporary structure_hint on_problems row_limit
        _ ->
            Panic.throw <| Illegal_Argument.Error ("Unsupported table type: " + Meta.get_qualified_type_name source_table)


## PRIVATE
   It should be run within a transaction and wrapped in `handle_upload_errors`.
internal_upload_in_memory_table source_table connection table_name primary_key temporary structure_hint on_problems:Problem_Behavior row_limit =
    In_Transaction.ensure_in_transaction <|
        verify_structure_hint structure_hint source_table.column_names
        structure = structure_hint.if_nothing source_table
        created_table_name = internal_create_table_structure connection table_name structure=structure primary_key=primary_key temporary=temporary on_problems=on_problems
        column_names = source_table.column_names

        ## `created_table_name.if_not_error` is used to ensure that if there are
           any dataflow errors up to this point, we want to propagate them and not
           continue. Otherwise, they could 'leak' to `Panic.rethrow` and be wrongly
           raised as panics.
        upload_status = created_table_name.if_not_error <|
            internal_translate_known_upload_errors source_table connection primary_key <|
                insert_template = make_batched_insert_template connection created_table_name column_names
                statement_setter = connection.dialect.get_statement_setter
                Panic.rethrow <|
                    expected_type_hints = align_structure connection structure . map .value_type
                    connection.jdbc_connection.batch_insert insert_template statement_setter source_table batch_size=default_batch_size expected_type_hints=expected_type_hints row_limit=row_limit

        upload_status.if_not_error <|
            connection.query (SQL_Query.Table_Name created_table_name)

## PRIVATE
   It should be run within a transaction and wrapped in `handle_upload_errors`.
internal_upload_database_table source_table connection table_name primary_key temporary structure_hint on_problems:Problem_Behavior row_limit =
    In_Transaction.ensure_in_transaction <|
        connection_check = if source_table.connection.jdbc_connection == connection.jdbc_connection then True else
            Error.throw (Unsupported_Database_Operation.Error "The Database table to be uploaded must be coming from the same connection as the connection on which the new table is being created. Cross-connection uploads are currently not supported. To work around this, you can first `.read` the table into memory and then upload it from memory to a different connection.")

        verify_structure_hint structure_hint source_table.column_names
        structure = structure_hint.if_nothing source_table
        connection_check.if_not_error <|
            # Warning: in some DBs, calling a DDL query in a transaction may commit it. We may have to have some special handling for this.
            created_table_name = internal_create_table_structure connection table_name structure=structure primary_key=primary_key temporary=temporary on_problems=on_problems
            upload_status = created_table_name.if_not_error <|
                internal_translate_known_upload_errors source_table connection primary_key <|
                    effective_source_table = case row_limit of
                        Nothing -> source_table
                        _ : Integer -> source_table.limit row_limit
                    ## We need to ensure that the columns in this statement are
                       matching positionally the columns in the newly created
                       table. But we create both from the same source table, so
                       that is guaranteed.
                    copy_into_statement = connection.dialect.generate_sql <|
                        Query.Insert_From_Select created_table_name effective_source_table.column_names effective_source_table.to_select_query
                    Panic.rethrow <| connection.execute_update copy_into_statement

            upload_status.if_not_error <|
                connection.query (SQL_Query.Table_Name created_table_name)
