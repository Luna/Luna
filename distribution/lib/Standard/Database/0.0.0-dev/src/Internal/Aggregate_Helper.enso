from Standard.Base import all
import Standard.Base.Errors.Deprecated.Deprecated
import Standard.Base.Errors.Illegal_Argument.Illegal_Argument

import Standard.Table.Internal.Aggregate_Column_Helper
import Standard.Table.Internal.Problem_Builder.Problem_Builder
from Standard.Table import Aggregate_Column
from Standard.Table.Errors import Floating_Point_Equality, No_Output_Columns

import project.DB_Table.DB_Table
import project.Dialect.Dialect
import project.Internal.DB_Wrapped_Error.DB_Wrapped_Error
import project.Internal.IR.Internal_Column.Internal_Column
import project.Internal.IR.SQL_Expression.SQL_Expression
import project.Internal.SQL_Type_Reference.SQL_Type_Reference
from project.Errors import Unsupported_Database_Operation

## PRIVATE
   Creates an `Internal_Column` that will represent the computed aggregate.

   Arguments:
   - table: The table owning the columns used in the aggregation.
   - aggregate: The description of the aggregation to compute.
   - as: The name for the created column.
   - dialect: The dialect of the database to generate the SQL for.
   - infer_return_type: A function that takes 3 arguments (name of the
     operation, list of input columns and a raw SQL IR Expression) and returns
     the inferred type for the aggregation.
   - problem_builder: A `Problem_Builder` instance used for reporting warnings.
make_aggregate_column : DB_Table -> Aggregate_Column -> Text -> Dialect -> (Any -> Any -> Any -> SQL_Type_Reference) -> Problem_Builder -> SQL_Expression
make_aggregate_column table aggregate as dialect infer_return_type problem_builder =
    is_non_empty_selector v = v.is_nothing.not && v.not_empty
    simple_aggregate op_kind columns =
        expression = dialect.cast_op_type op_kind columns (SQL_Expression.Operation op_kind (columns.map c->c.expression))
        sql_type_ref = infer_return_type op_kind columns expression
        Internal_Column.Value as sql_type_ref expression

    aggregate_with_order_by op_kind column order_by =
        order_bys = order_by.map sc->
            effective_ordering = if sc.column.value_type.is_text then Text_Ordering.Default else Nothing
            dialect.prepare_order_descriptor sc.column.as_internal sc.direction effective_ordering
        expression = SQL_Expression.Operation op_kind [column.expression]+order_bys
        sql_type_ref = infer_return_type op_kind [column] expression
        Internal_Column.Value as sql_type_ref expression

    dialect.check_aggregate_support aggregate . if_not_error <| case aggregate of
        Aggregate_Column.Group_By c _ ->
            Internal_Column.Value as c.sql_type_reference c.expression
        Aggregate_Column.Count _ -> simple_aggregate "COUNT_ROWS" []
        Aggregate_Column.Count_Distinct columns _ ignore_nothing -> if columns.is_empty then Error.throw (Illegal_Argument.Error "Count_Distinct must have at least one column.") else
            case ignore_nothing of
                True -> simple_aggregate "COUNT_DISTINCT" columns
                False -> simple_aggregate "COUNT_DISTINCT_INCLUDE_NULL" columns
        Aggregate_Column.Count_Not_Nothing c _ -> simple_aggregate "COUNT" [c]
        Aggregate_Column.Count_Nothing c _ -> simple_aggregate "COUNT_IS_NULL" [c]
        Aggregate_Column.Count_Not_Empty c _ -> simple_aggregate "COUNT_NOT_EMPTY" [c]
        Aggregate_Column.Count_Empty c _ -> simple_aggregate "COUNT_EMPTY" [c]
        Aggregate_Column.Percentile p c _ ->
            op_kind = "PERCENTILE"
            expression = SQL_Expression.Operation op_kind [SQL_Expression.Literal p.to_text, c.expression]
            sql_type_ref = infer_return_type op_kind [c] expression
            Internal_Column.Value as sql_type_ref expression
        Aggregate_Column.Mode c _ ->
            col = table.make_column c
            if col.value_type.is_floating_point then
                problem_builder.report_other_warning (Floating_Point_Equality.Error as)
            simple_aggregate "MODE" [c]
        Aggregate_Column.First c _ ignore_nothing order_by -> case is_non_empty_selector order_by of
            False -> Error.throw (Unsupported_Database_Operation.Error "`First` aggregation requires at least one `order_by` column.")
            True ->
                op = case ignore_nothing of
                    False -> "FIRST"
                    True -> "FIRST_NOT_NULL"
                aggregate_with_order_by op c order_by
        Aggregate_Column.Last c _ ignore_nothing order_by -> case is_non_empty_selector order_by of
            False -> Error.throw (Unsupported_Database_Operation.Error "`Last` aggregation requires at least one `order_by` column.")
            True ->
                op = case ignore_nothing of
                    False -> "LAST"
                    True -> "LAST_NOT_NULL"
                aggregate_with_order_by op c order_by
        Aggregate_Column.Maximum c _ -> simple_aggregate "MAX" [c]
        Aggregate_Column.Minimum c _ -> simple_aggregate "MIN" [c]
        Aggregate_Column.Shortest c _ -> simple_aggregate "SHORTEST" [c]
        Aggregate_Column.Longest c _ -> simple_aggregate "LONGEST" [c]
        Aggregate_Column.Standard_Deviation c _ population -> case population of
            True -> simple_aggregate "STDDEV_POP" [c]
            False -> simple_aggregate "STDDEV_SAMP" [c]
        Aggregate_Column.Concatenate c _ separator prefix suffix quote_char ->
            base_args = [c.expression, SQL_Expression.Constant separator, SQL_Expression.Constant prefix, SQL_Expression.Constant suffix]
            op_kind = case quote_char.is_empty of
                True -> "CONCAT"
                False -> "CONCAT_QUOTE_IF_NEEDED"
            effective_args = case op_kind of
                "CONCAT_QUOTE_IF_NEEDED" ->
                    base_args+[SQL_Expression.Constant quote_char]
                "CONCAT" -> base_args
            expression = SQL_Expression.Operation op_kind effective_args
            sql_type_ref = infer_return_type op_kind [c] expression
            Internal_Column.Value as sql_type_ref expression
        Aggregate_Column.Sum c _ -> simple_aggregate "SUM" [c]
        Aggregate_Column.Average c _ -> simple_aggregate "AVG" [c]
        Aggregate_Column.Median c _ -> simple_aggregate "MEDIAN" [c]

## PRIVATE
   Implementation for the `DB_Table.aggregate` method.
aggregate table:DB_Table group_by:(Vector | Text | Integer | Regex) columns:Vector error_on_missing_columns:Boolean on_problems:Problem_Behavior =
    normalized_group_by = Vector.unify_vector_or_element group_by
    if normalized_group_by.is_empty && columns.is_empty then Error.throw (No_Output_Columns.Error "No columns specified in aggregate.") else
        ## This is a fix for #10321 - if the source query contains an ORDER BY,
           we need to push it into a subquery to not interfere with aggregations.
        base_table = if table.context.orders.not_empty then table.as_subquery else table

        validated = Aggregate_Column_Helper.prepare_aggregate_columns base_table.column_naming_helper normalized_group_by columns base_table error_on_missing_columns=error_on_missing_columns

        key_columns = validated.key_columns
        key_problems = key_columns.flat_map internal_column->
            column = base_table.make_column internal_column
            case column.value_type.is_floating_point of
                True -> [Floating_Point_Equality.Error column.name]
                False -> []
        on_problems.attach_problems_before validated.problems+key_problems <|
            resolved_aggregates = validated.valid_columns
            key_expressions = key_columns.map .expression
            dialect = base_table.connection.dialect

            problem_builder = Problem_Builder.new
            result = default_build_aggregate base_table dialect key_expressions resolved_aggregates problem_builder
            new_ctx = result.first
            built_aggregates = result.second
            partitioned = built_aggregates.partition (_.is_a DB_Wrapped_Error)

            new_columns = partitioned.second
            problem_builder.attach_problems_before on_problems <|
                problems = partitioned.first.map .value
                on_problems.attach_problems_before problems <|
                    handle_no_output_columns =
                        first_problem = if problems.is_empty then Nothing else problems.first
                        Error.throw (No_Output_Columns.Error first_problem)
                    if new_columns.is_empty then handle_no_output_columns else
                        ## Subquery is needed to avoid unexpected interactions with future transformations of the Table.
                           We could design optimizations that will be able to elide it.
                        result = base_table.updated_context_and_columns new_ctx new_columns subquery=True
                        if validated.old_style.not then result else
                            Warning.attach (Deprecated.Warning "Standard.Table.Aggregate_Column.Aggregate_Column" "Group_By" "Deprecated: `Group_By` constructor has been deprecated, use the `group_by` argument instead.") result

## PRIVATE
default_build_aggregate base_table dialect key_expressions resolved_aggregates problem_builder =
    new_ctx = base_table.context.set_groups key_expressions
    ## TODO [RW] here we will perform as many fetches as there are
       aggregate columns, but technically we could perform just one
       fetch fetching all column types - TODO we should do that. We can
       do it here by creating a builder that will gather all requests
       from the executed callbacks and create Lazy references that all
       point to a single query.
       See #6118.
    infer_from_database_callback expression =
        SQL_Type_Reference.new base_table.connection base_table.context expression
    type_mapping = dialect.get_type_mapping
    infer_return_type op_kind columns expression =
        type_mapping.infer_return_type infer_from_database_callback op_kind columns expression
    results = resolved_aggregates.map p->
        agg = p.second
        as = p.first
        result = make_aggregate_column base_table agg as dialect infer_return_type problem_builder
        ## If the `result` did contain an error, we catch it to be
           able to store it in a vector and then we will partition the
           created columns and failures.
        result.catch Any error->(DB_Wrapped_Error.Value error)
    Pair.new new_ctx results
