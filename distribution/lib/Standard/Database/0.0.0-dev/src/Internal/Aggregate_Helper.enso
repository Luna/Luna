from Standard.Base import all
import Standard.Base.Errors.Common.No_Such_Method
import Standard.Base.Errors.Deprecated.Deprecated
import Standard.Base.Errors.Illegal_Argument.Illegal_Argument

import Standard.Table.Internal.Aggregate_Column_Helper
import Standard.Table.Internal.Problem_Builder.Problem_Builder
from Standard.Table import Aggregate_Column
from Standard.Table.Aggregate_Column.Aggregate_Column import all
from Standard.Table.Errors import Floating_Point_Equality, No_Output_Columns

import project.DB_Table.DB_Table
import project.Dialect.Dialect
import project.Internal.Common.Row_Number_Helpers
import project.Internal.DB_Wrapped_Error.DB_Wrapped_Error
import project.Internal.IR.Context.Context
import project.Internal.IR.Internal_Column.Internal_Column
import project.Internal.IR.SQL_Expression.SQL_Expression
import project.Internal.SQL_Type_Reference.SQL_Type_Reference
from project.Errors import Unsupported_Database_Operation

## PRIVATE
   Creates an `Internal_Column` that will represent the computed aggregate.

   Arguments:
   - table: The table owning the columns used in the aggregation.
   - aggregate: The description of the aggregation to compute.
   - as: The name for the created column.
   - dialect: The dialect of the database to generate the SQL for.
   - infer_return_type: A function that takes 3 arguments (name of the
     operation, list of input columns and a raw SQL IR Expression) and returns
     the inferred type for the aggregation.
   - problem_builder: A `Problem_Builder` instance used for reporting warnings.
make_aggregate_column : DB_Table -> Aggregate_Column -> Text -> Dialect -> (Any -> Any -> Any -> SQL_Type_Reference) -> Problem_Builder -> Internal_Column
make_aggregate_column table aggregate as dialect infer_return_type problem_builder -> Internal_Column =
    is_non_empty_selector v = v.is_nothing.not && v.not_empty
    simple_aggregate op_kind columns =
        expression = dialect.cast_op_type op_kind columns (SQL_Expression.Operation op_kind (columns.map c->c.expression))
        sql_type_ref = infer_return_type op_kind columns expression
        Internal_Column.Value as sql_type_ref expression

    aggregate_with_order_by op_kind column order_by =
        order_bys = order_by.map sc->
            effective_ordering = if sc.column.value_type.is_text then Text_Ordering.Default else Nothing
            dialect.prepare_order_descriptor sc.column.as_internal sc.direction effective_ordering
        expression = SQL_Expression.Operation op_kind [column.expression]+order_bys
        sql_type_ref = infer_return_type op_kind [column] expression
        Internal_Column.Value as sql_type_ref expression

    dialect.check_aggregate_support aggregate . if_not_error <| case aggregate of
        Aggregate_Column.Group_By c _ ->
            Internal_Column.Value as c.sql_type_reference c.expression
        Aggregate_Column.Count _ -> simple_aggregate "COUNT_ROWS" []
        Aggregate_Column.Count_Distinct columns _ ignore_nothing -> if columns.is_empty then Error.throw (Illegal_Argument.Error "Count_Distinct must have at least one column.") else
            case ignore_nothing of
                True -> simple_aggregate "COUNT_DISTINCT" columns
                False -> simple_aggregate "COUNT_DISTINCT_INCLUDE_NULL" columns
        Aggregate_Column.Count_Not_Nothing c _ -> simple_aggregate "COUNT" [c]
        Aggregate_Column.Count_Nothing c _ -> simple_aggregate "COUNT_IS_NULL" [c]
        Aggregate_Column.Count_Not_Empty c _ -> simple_aggregate "COUNT_NOT_EMPTY" [c]
        Aggregate_Column.Count_Empty c _ -> simple_aggregate "COUNT_EMPTY" [c]
        Aggregate_Column.Percentile p c _ ->
            op_kind = "PERCENTILE"
            expression = SQL_Expression.Operation op_kind [SQL_Expression.Literal p.to_text, c.expression]
            sql_type_ref = infer_return_type op_kind [c] expression
            Internal_Column.Value as sql_type_ref expression
        Aggregate_Column.Mode c _ ->
            col = table.make_column c
            if col.value_type.is_floating_point then
                problem_builder.report_other_warning (Floating_Point_Equality.Error as)
            simple_aggregate "MODE" [c]
        Aggregate_Column.First c _ ignore_nothing order_by -> case is_non_empty_selector order_by of
            False -> Error.throw (Unsupported_Database_Operation.Error "`First` aggregation requires at least one `order_by` column.")
            True ->
                op = case ignore_nothing of
                    False -> "FIRST"
                    True -> "FIRST_NOT_NULL"
                aggregate_with_order_by op c order_by
        Aggregate_Column.Last c _ ignore_nothing order_by -> case is_non_empty_selector order_by of
            False -> Error.throw (Unsupported_Database_Operation.Error "`Last` aggregation requires at least one `order_by` column.")
            True ->
                op = case ignore_nothing of
                    False -> "LAST"
                    True -> "LAST_NOT_NULL"
                aggregate_with_order_by op c order_by
        Aggregate_Column.Maximum c _ -> simple_aggregate "MAX" [c]
        Aggregate_Column.Minimum c _ -> simple_aggregate "MIN" [c]
        Aggregate_Column.Shortest c _ -> simple_aggregate "SHORTEST" [c]
        Aggregate_Column.Longest c _ -> simple_aggregate "LONGEST" [c]
        Aggregate_Column.Standard_Deviation c _ population -> case population of
            True -> simple_aggregate "STDDEV_POP" [c]
            False -> simple_aggregate "STDDEV_SAMP" [c]
        Aggregate_Column.Concatenate c _ separator prefix suffix quote_char ->
            base_args = [c.expression, SQL_Expression.Constant separator, SQL_Expression.Constant prefix, SQL_Expression.Constant suffix]
            op_kind = case quote_char.is_empty of
                True -> "CONCAT"
                False -> "CONCAT_QUOTE_IF_NEEDED"
            effective_args = case op_kind of
                "CONCAT_QUOTE_IF_NEEDED" ->
                    base_args+[SQL_Expression.Constant quote_char]
                "CONCAT" -> base_args
            expression = SQL_Expression.Operation op_kind effective_args
            sql_type_ref = infer_return_type op_kind [c] expression
            Internal_Column.Value as sql_type_ref expression
        Aggregate_Column.Sum c _ -> simple_aggregate "SUM" [c]
        Aggregate_Column.Average c _ -> simple_aggregate "AVG" [c]
        Aggregate_Column.Median c _ -> simple_aggregate "MEDIAN" [c]

## PRIVATE
   Implementation for the `DB_Table.aggregate` method.
aggregate table:DB_Table group_by:(Vector | Text | Integer | Regex) columns:Vector error_on_missing_columns:Boolean on_problems:Problem_Behavior =
    normalized_group_by = Vector.unify_vector_or_element group_by
    if normalized_group_by.is_empty && columns.is_empty then Error.throw (No_Output_Columns.Error "No columns specified in aggregate.") else
        ## This is a fix for #10321 - if the source query contains an ORDER BY,
           we need to push it into a subquery to not interfere with aggregations.
        base_table = if table.context.orders.not_empty then table.as_subquery else table

        validated = Aggregate_Column_Helper.prepare_aggregate_columns base_table.column_naming_helper normalized_group_by columns base_table error_on_missing_columns=error_on_missing_columns

        key_columns = validated.key_columns
        key_problems = key_columns.flat_map internal_column->
            column = base_table.make_column internal_column
            case column.value_type.is_floating_point of
                True -> [Floating_Point_Equality.Error column.name]
                False -> []
        on_problems.attach_problems_before validated.problems+key_problems <|
            resolved_aggregates = validated.valid_columns
            dialect = base_table.connection.dialect

            problem_builder = Problem_Builder.new
            # If the dialect defines `custom_build_aggregate` we will use it, falling back to the default implementation if not defined.
            aggregate_builder = Panic.catch No_Such_Method (dialect.custom_build_aggregate) _->
                default_build_aggregate dialect
            result = aggregate_builder base_table key_columns resolved_aggregates problem_builder
            new_ctx = result.first
            built_aggregates = result.second
            partitioned = built_aggregates.partition (_.is_a DB_Wrapped_Error)

            new_columns = partitioned.second
            problem_builder.attach_problems_before on_problems <|
                problems = partitioned.first.map .value
                on_problems.attach_problems_before problems <|
                    handle_no_output_columns =
                        first_problem = if problems.is_empty then Nothing else problems.first
                        Error.throw (No_Output_Columns.Error first_problem)
                    if new_columns.is_empty then handle_no_output_columns else
                        ## Subquery is needed to avoid unexpected interactions with future transformations of the Table.
                           We could design optimizations that will be able to elide it.
                        result = base_table.updated_context_and_columns new_ctx new_columns subquery=True
                        if validated.old_style.not then result else
                            Warning.attach (Deprecated.Warning "Standard.Table.Aggregate_Column.Aggregate_Column" "Group_By" "Deprecated: `Group_By` constructor has been deprecated, use the `group_by` argument instead.") result

## PRIVATE
default_build_aggregate dialect base_table key_columns resolved_aggregates problem_builder =
    key_expressions = key_columns.map .expression
    new_ctx = base_table.context.set_groups key_expressions
    # TODO new_ctx fits here? I think it makes more sense than base_table.context that used to be here
    infer_return_type = make_infer_return_type dialect base_table.connection new_ctx
    results = resolved_aggregates.map p->
        agg = p.second
        as = p.first
        result = make_aggregate_column base_table agg as dialect infer_return_type problem_builder
        ## If the `result` did contain an error, we catch it to be
           able to store it in a vector and then we will partition the
           created columns and failures.
        result.catch Any error->(DB_Wrapped_Error.Value error)
    Pair.new new_ctx results

## PRIVATE
make_infer_return_type dialect connection context =
    ## TODO [RW] here we will perform as many fetches as there are
       aggregate columns, but technically we could perform just one
       fetch fetching all column types - TODO we should do that. We can
       do it here by creating a builder that will gather all requests
       from the executed callbacks and create Lazy references that all
       point to a single query.
       See #6118.
    infer_from_database_callback expression =
        SQL_Type_Reference.new connection context expression
    type_mapping = dialect.get_type_mapping
    infer_return_type op_kind columns expression =
        type_mapping.infer_return_type infer_from_database_callback op_kind columns expression
    infer_return_type

## PRIVATE
   An implementation that can be used for `custom_build_aggregate` in dialects
   that do not implement First/Last aggregations natively and instead need to
   use a ROW_NUMBER sub-query trick. This is e.g. SQLite and Snowflake.

   If a First/Last aggregation is requested, a sub-query containing a row number
   with requested ordering is created, and that row number expression will be
   passed to the aggregate instead of the ordering.
   If several aggregations with different orderings are requested, a separate
   row number column is created for each ordering. Aggregations with the same
   ordering will re-use the same column.

   If no First/Last aggregations are requested, no sub-queries are created - in
   fact we just delegate to the default implementation.
build_aggregate_with_row_number_for_first_last dialect base_table key_columns resolved_aggregates problem_builder =
    if (has_first_last resolved_aggregates).not then default_build_aggregate dialect base_table key_columns resolved_aggregates problem_builder else
        needed_orderings = resolved_aggregates.flat_map agg-> case agg.second of
            Aggregate_Column.First _ _ _ order_by -> [order_by]
            Aggregate_Column.Last _ _ _ order_by -> [order_by]
            _ -> []

        # This function will infer return type at the context of the current query - used to extend it with row numbers.
        # infer_return_type_in_orderings = make_infer_return_type dialect base_table.connection base_table.context
        name_generator = base_table.column_naming_helper.create_unique_name_strategy
        name_generator.mark_used base_table.column_names
        key_expressions_for_orderings = key_columns.map .expression
        numbering_columns = Dictionary.from_vector <| needed_orderings.distinct.map ordering->
            name = name_generator.make_unique "row-number"
            order_descriptors = dialect.prepare_order_descriptor ordering.column ordering.direction text_ordering=Nothing
            expression = Row_Number_Helpers.make_row_number 1 1 order_descriptors key_expressions_for_orderings
            # We can ignore the type for this column as it is used only internally.
            column = Internal_Column.Value name SQL_Type_Reference.null expression
            [ordering, column]

        subquery_setup = base_table.context.as_subquery base_table.name [base_table.internal_columns, numbering_columns.values]
        updated_numbering_columns = numbering_columns.map subquery_setup.remap_column

        # The context referring to the outer query that contains the subquery with additional columns and also is now grouped for the aggregation:
        remapped_key_expressions = key_columns.map key_column->
            subquery_setup.remap_column key_column . expression
        new_ctx = (Context.for_subquery subquery_setup.subquery).set_groups remapped_key_expressions

        # This function will infer return type at the context of the subquery with aggregation groupings.
        infer_return_type_in_new_context = make_infer_return_type dialect base_table.connection new_ctx
        results = resolved_aggregates.map p->
            original_aggregate = p.second
            as = p.first
            updated_aggregate = map_column_inputs subquery_setup.remap_column original_aggregate

            make_first_last op_kind =
                row_number = updated_numbering_columns.at (original_aggregate.order_by)
                op = case updated_aggregate.ignore_nothing of
                    False -> op_kind
                    True  -> op_kind + "_NOT_NULL"
                # We just inherit the type of the source column, as the FIRST/LAST element of a column should have the same type.
                sql_type_reference = updated_aggregate.column.sql_type_reference
                Internal_Column.Value as sql_type_reference (SQL_Expression.Operation op [updated_aggregate.column.expression, row_number.expression])

            case updated_aggregate of
                Aggregate_Column.First _ _ _ _ ->
                    make_first_last "FIRST"
                Aggregate_Column.Last _ _ _ _ ->
                    make_first_last "LAST"
                _ ->
                    # For all other aggregates we fallback to the default implementation.
                    result = make_aggregate_column base_table updated_aggregate as dialect infer_return_type_in_new_context problem_builder
                    result.catch Any error->(DB_Wrapped_Error.Value error)
        Pair.new new_ctx results


## PRIVATE
has_first_last resolved_aggregates = resolved_aggregates.any agg->
    case agg.second of
        Aggregate_Column.First _ _ _ _ -> True
        Aggregate_Column.Last _ _ _ _ -> True
        _ -> False

## PRIVATE
   Applies a mapping to column inputs of the aggregate.
   It does not modify the columns inside of the `order_by` argument though.
map_column_inputs f:Function aggregate_column:Aggregate_Column -> Aggregate_Column =
    case aggregate_column of
        Group_By c as -> Group_By (f c) as
        Count as -> Count as
        Count_Distinct c as ignore_nothing ->
            Count_Distinct (c.map f) as ignore_nothing
        Count_Not_Nothing c as -> Count_Not_Nothing (f c) as
        Count_Nothing c as -> Count_Nothing (f c) as
        Count_Not_Empty c as -> Count_Not_Empty (f c) as
        Count_Empty c as ->  Count_Empty (f c) as
        Sum c as -> Sum (f c) as
        Average c as -> Average (f c) as
        Median c as -> Median (f c) as
        Percentile p c as -> Percentile p (f c) as
        Mode c as -> Mode (f c) as
        Standard_Deviation c as population -> Standard_Deviation (f c) as population
        Concatenate c as separator prefix suffix quote_char -> Concatenate (f c) as separator prefix suffix quote_char
        First c as ignore_nothing order_by -> First (f c) as ignore_nothing order_by
        Last c as ignore_nothing order_by -> Last (f c) as ignore_nothing order_by
        Maximum c as -> Maximum (f c) as
        Minimum c as -> Minimum (f c) as
        Shortest c as -> Shortest (f c) as
        Longest c as -> Longest (f c) as
