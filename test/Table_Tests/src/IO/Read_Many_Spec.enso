from Standard.Base import all
import Standard.Base.Errors.Illegal_Argument.Illegal_Argument

from Standard.Table import all
from Standard.Table.Errors import Invalid_Value_Type
from Standard.Database import all

from Standard.Test import all

from project.Util import all
from project.Common_Table_Operations.Util import within_table

main filter=Nothing =
    suite = Test.build suite_builder->
        add_specs suite_builder
    suite.run_with_filter filter

type Lazy_Ref
    Value ~get

add_specs suite_builder =
    suite_builder.group "Data.read_many" group_builder->
        # One File and one Text path
        files_vector = [enso_project.data / "empty.txt", (enso_project.data / "sample.tsv") . path]
        sample_table = Lazy_Ref.Value <|
            (enso_project.data / "sample.tsv") . read

        check_common_columns table =
            table.at "Value" . to_vector . should_equal ["" , Nothing, Nothing]
            table.at "a" . to_vector     . should_equal [Nothing, 1, 4]
            table.at "b" . to_vector     . should_equal [Nothing, 2, 5]
            table.at "c" . to_vector     . should_equal [Nothing, 3, 6]
        check_returned_vector vec =
            vec.should_be_a Vector
            vec.length . should_equal 2
            vec.first . should_equal ""
            vec.second . should_equal sample_table.get

        group_builder.specify "should read files listed in a Column" <|
            column = Column.from_vector "Col" files_vector
            r1 = Data.read_many column return=..Vector
            check_returned_vector r1
            Problems.assume_no_problems r1

            r2 = Data.read_many column return=..Table_Of_Objects
            r2.should_be_a Table
            r2.column_names . should_equal ["Col", "Value"]
            r2.at "Col" . to_vector . should_equal files_vector
            check_returned_vector (r2.at "Value" . to_vector)

        group_builder.specify "should read files listed in a single column Table" <|
            table1 = Table.new [["Some column", files_vector]]
            r1 = Data.read_many table1 return=..Vector
            check_returned_vector r1

            r2 = Data.read_many table1 return=..Table_Of_Objects
            r2.should_be_a Table
            r2.column_names . should_equal ["Some column", "Value"]
            r2.at "Some column" . to_vector . should_equal files_vector
            check_returned_vector (r2.at "Value" . to_vector)

        group_builder.specify "should read files listed in a Table with `path` column" <|
            table1 = Table.new [["X", [1, 2]], ["path", files_vector]]
            r1 = Data.read_many table1 return=..Vector
            check_returned_vector r1
            Problems.assume_no_problems r1

            r2 = Data.read_many table1 return=..Table_Of_Objects
            r2.should_be_a Table
            r2.column_names . should_equal ["X", "path", "Value"]
            r2.at "X" . to_vector . should_equal [1, 2]
            r2.at "path" . to_vector . should_equal files_vector
            check_returned_vector (r2.at "Value" . to_vector)

            # Test that this is really case insensitive
            table3 = Table.new [["X", [1, 2]], ["pAtH", files_vector]]
            r3 = Data.read_many table3 return=..Table_Of_Objects
            r3.should_be_a Table
            r3.column_names . should_equal ["X", "pAtH", "Value"]
            check_returned_vector (r3.at "Value" . to_vector)

        group_builder.specify "will fail if no `path` column can be found or its ambiguous" <|
            table1 = Table.new [["X", [1, 2]], ["Y", files_vector]]
            r1 = Data.read_many table1 return=..Vector
            r1.should_fail_with Illegal_Argument

            table2 = Table.new [["X", [1, 2]], ["path", files_vector], ["Path", [3, 4]]]
            r2 = Data.read_many table2 return=..Vector
            r2.should_fail_with Illegal_Argument

        group_builder.specify "fails if a DB Table or Column is provided, telling to materialize first to in-memory" <|
            connection = Database.connect SQLite.In_Memory
            paths_vector = files_vector.map x-> case x of
                f : File -> f.path
                p : Text -> p

            table = (Table.new [["path", paths_vector]]).select_into_database_table connection "test_table" temporary=True
            r = Data.read_many table return=..Vector
            r.should_fail_with Illegal_Argument

            col = table.at "path"
            r2 = Data.read_many col return=..Vector
            r2.should_fail_with Illegal_Argument

        group_builder.specify "fails if a column of invalid type is provided" <|
            table = Table.new [["path", [1, 2]], ["X", [33, 44]]]

            Data.read_many table . should_fail_with Invalid_Value_Type
            Data.read_many (table.at "path") . should_fail_with Invalid_Value_Type
            Data.read_many (table.select_columns ["X"]) . should_fail_with Invalid_Value_Type

        group_builder.specify "if input is a Column or Table, the return type will default to a merged table" <|
            r1 = Data.read_many (Column.from_vector "my column" files_vector)
            r1.should_be_a Table
            r1.column_names . should_equal ["my column", "Value", "a", "b", "c"]
            r1.at "my column" . to_vector . should_equal [files_vector.first, files_vector.second, files_vector.second]
            check_common_columns r1

            r2 = Data.read_many (Table.new [["X", [100, 200]], ["Path", files_vector], ["Y", [300, 400]]])
            r2.should_be_a Table
            r2.column_names . should_equal ["X", "Path", "Y", "Value", "a", "b", "c"]
            # The second row is duplicated because it gets expanded along with the table that was loaded that has 2 rows
            r2.at "X" . to_vector . should_equal [100, 200, 200]
            r2.at "Y" . to_vector . should_equal [300, 400, 400]
            check_common_columns r2

        group_builder.specify "if input is a Vector, the default can be overridden to return a Table" <|
            r1 = Data.read_many files_vector return=..Table_Of_Objects
            r1.should_be_a Table
            r1.column_names . should_equal ["Path", "Value"]
            r1.at "Path" . to_vector . should_equal files_vector
            check_returned_vector (r1.at "Value" . to_vector)

            r2 = Data.read_many files_vector return=..Merged_Table
            r2.should_be_a Table
            r2.column_names . should_equal ["Path", "Value", "a", "b", "c"]
            check_common_columns r2

        group_builder.specify "will merge files that read as non-Table values into a Table using reasonable defaults" <|
            base_dir = enso_project.data / "transient" / "read_many_test"
            base_dir.delete_if_exists recursive=True
            base_dir.create_directory . should_succeed
            Panic.with_finalizer (base_dir.delete recursive=True) <|
                # raw JS Object - we want it to expand to a single row - same as if it was in a 1-element array
                (JS_Object.from_pairs [["a", 1], ["b", 2]]).to_json.write (base_dir / "1_js_object.json")

                # array of JS objects
                [JS_Object.from_pairs [["a", 30], ["b", 40], ["c", "foobar"]], JS_Object.from_pairs [["a", 50], ["b", 60]]].to_json.write (base_dir / "2_js_array.json")

                # JS array of numbers
                [100, 200, 300].to_json.write (base_dir / "3_js_numbers.json")

                # a Table
                (Table.new [["a", [-1, -2]], ["d", [-4, -5]]]).write (base_dir / "4_table.tsv")

                # a plain text value
                "Hi!".write (base_dir / "5_plain_text.txt")

                # JS null
                "null".write (base_dir / "6_js_null.json")

                # a JS string
                '"str"'.write (base_dir / "7_js_string.json")

                files = Data.list base_dir . sort on=.name
                IO.println (Meta.type_of files.first)
                r = Data.read_many files return=..Merged_Table
                r.should_be_a Table

                within_table r <|
                    # We transform the Path to just file name
                    rows = (r.set (r.at "Path" . map .name) "Path").rows.map .to_vector

                    null = Nothing
                    r.column_names . should_equal ["Path",               "a",  "b",      "c", "Value",  "d"]
                    rows.at 0 .      should_equal ["1_js_object.json",     1,    2,     null,    null, null]
                    rows.at 1 .      should_equal ["2_js_array.json",     30,   40, "foobar",    null, null]
                    rows.at 2 .      should_equal ["2_js_array.json",     50,   60,     null,    null, null]
                    rows.at 3 .      should_equal ["3_js_numbers.json", null, null,     null,     100, null]
                    rows.at 4 .      should_equal ["3_js_numbers.json", null, null,     null,     200, null]
                    rows.at 5 .      should_equal ["3_js_numbers.json", null, null,     null,     300, null]
                    rows.at 6 .      should_equal ["4_table.tsv",         -1, null,     null,    null,   -4]
                    rows.at 7 .      should_equal ["4_table.tsv",         -2, null,     null,    null,   -5]
                    rows.at 8 .      should_equal ["5_plain_text.txt",  null, null,     null,   "Hi!", null]
                    rows.at 9 .      should_equal ["6_js_null.json",    null, null,     null,    null, null]
                    rows.at 10 .     should_equal ["7_js_string.json",  null, null,     null,   "str", null]

                    r.at "a" . value_type     . should_equal Value_Type.Integer
                    r.at "b" . value_type     . should_equal Value_Type.Integer
                    r.at "c" . value_type     . should_equal Value_Type.Char
                    r.at "Value" . value_type . should_equal Value_Type.Mixed
                    r.at "d" . value_type     . should_equal Value_Type.Integer

        group_builder.specify "will rename duplicated columns, keeping columns from the input unchanged" <|
            tmp_file = enso_project.data / "transient" / "table.csv"
            (Table.new [["Path", [1]], ["Col", [2]]]).write tmp_file on_existing_file=..Overwrite . should_succeed
            Panic.with_finalizer tmp_file.delete <|
                col = Column.from_vector "Col" [tmp_file.path]
                r = Data.read_many col return=..Merged_Table
                r.column_names . should_equal ["Col", "Path", "Col 1"]
                r.at "Col" . to_vector . should_equal [tmp_file.path]
                r.at "Path" . to_vector . should_equal [1]
                r.at "Col 1" . to_vector . should_equal [2]

                table = Table.new [["Path", [tmp_file.path]], ["Col", ["X"]], ["Value", ["Y"]]]
                r2 = Data.read_many table return=..Merged_Table
                r2.column_names . should_equal ["Path", "Col", "Value", "Path 1", "Col 1"]
                r2.at "Path" . to_vector . should_equal [tmp_file.path]
                r2.at "Col" . to_vector . should_equal ["X"]
                r2.at "Value" . to_vector . should_equal ["Y"]
                r2.at "Path 1" . to_vector . should_equal [1]
                r2.at "Col 1" . to_vector . should_equal [2]

                r3 = Data.read_many table return=..Table_Of_Objects
                r3.column_names . should_equal ["Path", "Col", "Value", "Value 1"]
                r3.at "Path" . to_vector . should_equal [tmp_file.path]
                r3.at "Col" . to_vector . should_equal ["X"]
                r3.at "Value" . to_vector . should_equal ["Y"]
                r3.at "Value 1" . first . should_be_a Table
