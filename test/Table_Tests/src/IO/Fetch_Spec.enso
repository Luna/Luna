from Standard.Base import all
import Standard.Base.Data.Base_64.Base_64
import Standard.Base.Errors.File_Error.File_Error
import Standard.Base.Network.HTTP.Response.Response
import Standard.Base.Runtime.Context
from Standard.Base.Network.HTTP import http_get_num_response_cache_entries 

from Standard.Table import all
import Standard.Table.Errors.Invalid_JSON_Format

from Standard.Test import all

from enso_dev.Base_Tests.Network.Http.Http_Test_Setup import base_url_with_slash, pending_has_url

import project.Util

main filter=Nothing =
    suite = Test.build suite_builder->
        add_specs suite_builder
    suite.run_with_filter filter


add_specs suite_builder =
    suite_builder.group "fetching files using HTTP" pending=pending_has_url group_builder->
        group_builder.specify "fetching json" <| Test.with_retries <|
            r = Data.fetch base_url_with_slash+"testfiles/table.json"
            expected_table  = Table.from_rows ["A", "B"] [[1, "x"], [3, "y"]]
            r.to Table . should_equal expected_table

        group_builder.specify "fetching csv" <| Test.with_retries <|
            url = base_url_with_slash+"testfiles/table.csv"
            r = Data.fetch url
            expected_table  = Table.from_rows ["A", "B"] [[1, "x"], [3, "y"]]

            r.should_be_a Table
            r.should_equal expected_table

            r2 = url.to_uri.fetch
            r2.should_be_a Table
            r2.should_equal expected_table

        group_builder.specify "fetching xls" <| Test.with_retries <|
            url = base_url_with_slash+"testfiles/table.xls"
            r = Data.fetch url
            expected_table  = Table.from_rows ["A", "B"] [[1, "x"], [3, "y"]]

            r.should_be_a Excel_Workbook
            r.sheet_names . should_equal ["MyTestSheet"]
            r.read "MyTestSheet" . should_equal expected_table

            r2 = Data.fetch url format=Raw_Response . decode (..Sheet "MyTestSheet")
            r2.should_be_a Table
            r2.should_equal expected_table

        group_builder.specify "fetching xlsx" <| Test.with_retries <|
            url = base_url_with_slash+"testfiles/table.xlsx"
            r = Data.fetch url
            expected_table  = Table.from_rows ["A", "B"] [[1, "x"], [3, "y"]]

            r.should_be_a Excel_Workbook
            r.sheet_names . should_equal ["MyTestSheet"]
            r.read "MyTestSheet" . should_equal expected_table

            r2 = Data.fetch url format=Raw_Response . decode (..Sheet "MyTestSheet")
            r2.should_be_a Table
            r2.should_equal expected_table

            r3 = url.to_uri.fetch format=Raw_Response . decode (..Sheet "MyTestSheet")
            r3.should_be_a Table
            r3.should_equal expected_table

        group_builder.specify "format detection based on Content-Type and Content-Disposition" <| Test.with_retries <|
            content = 'A,B\n1,x\n3,y'
            uri = URI.from (base_url_with_slash+"test_headers")
                . add_query_argument "base64_response_data" (Base_64.encode_text content)
            expected_table = Table.from_rows ["A", "B"] [[1, "x"], [3, "y"]]

            r0 = uri.fetch
            # No automatic parsing, because no content type information is specified.
            r0.should_be_a Response
            r0.content_type . should_equal Nothing
            r0.get_header "Content-Disposition" . should_equal Nothing

            r1 = (uri.add_query_argument "Content-Type" "text/csv").fetch
            r1.should_equal expected_table

            r2 = (uri.add_query_argument "Content-Disposition" 'attachment; filename="my_table.csv"').fetch
            r2.should_equal expected_table

            # If the disposition suggest a text file, we will parse as text:
            r3 = (uri.add_query_argument "Content-Disposition" 'attachment; filename="text.txt"').fetch
            r3.should_be_a Text
            r3.should_equal content

            # Reinterpreting as TSV:
            r4 = (uri.add_query_argument "Content-Type" "text/tab-separated-values").fetch
            r4.should_equal (Table.from_rows ["Column 1"] [["A,B"], ["1,x"], ["3,y"]])

    suite_builder.group "Response caching" group_builder->
        # Returns true if the cache was used.
        # Does not clear the cache first.
        request_and_get_counts uri method headers cache_policy=Cache_Policy.Default =
            before_count = http_get_num_response_cache_entries
            response = Data.fetch uri method headers cache_policy=cache_policy
            response.code.is_success . should_be_true
            after_count = http_get_num_response_cache_entries
            [before_count, after_count]

        # Only use with GET.
        # Clears the cache first.
        with_and_without_caching uri headers =
            Data.clear_response_cache
            request_and_get_counts uri HTTP_Method.Get headers . should_equal [0, 1]
            request_and_get_counts uri HTTP_Method.Get headers . should_equal [1, 1]
            Data.clear_response_cache
            request_and_get_counts uri HTTP_Method.Get headers cache_policy=..Cache_Responses . should_equal [0, 1]
            request_and_get_counts uri HTTP_Method.Get headers cache_policy=..Cache_Responses . should_equal [1, 1]
            Data.clear_response_cache
            request_and_get_counts uri HTTP_Method.Get headers cache_policy=..Dont_Cache_Responses . should_equal [0, 0]
            request_and_get_counts uri HTTP_Method.Get headers cache_policy=..Dont_Cache_Responses . should_equal [0, 0]

        uri0 = 'http://localhost:8080/test_download?max-age=16&length=100'
        headers0 = [Header.new "A-Header" "a-header-value", Header.new "A-Header" "a-header-value"]

        group_builder.specify "Should cache responses" pending=pending_has_url <| Test.with_retries <|
            with_and_without_caching uri0 headers0
        ##
            group_builder.specify "Should not cache for methods other than GET" pending=pending_has_url <| Test.with_retries <|
            group_builder.specify "Should not allow a cache policy for methods other than GET" pending=pending_has_url <| Test.with_retries <|
            group_builder.specify "Should be able to clear caches" pending=pending_has_url <| Test.with_retries <|
            group_builder.specify "Cache key should depend on the URI" pending=pending_has_url <| Test.with_retries <|
            group_builder.specify "Cache key should depend on the headers" pending=pending_has_url <| Test.with_retries <|
            group_builder.specify "Cache policy should work for Data.read" pending=pending_has_url <| Test.with_retries <|
            group_builder.specify "Cache policy should work for Data.fetch" pending=pending_has_url <| Test.with_retries <|
            group_builder.specify "Cache policy should work for Data.download" pending=pending_has_url <| Test.with_retries <|
            group_builder.specify "The cache should expire stale entries" pending=pending_has_url <| Test.with_retries <|
            group_builder.specify "The cache should use the Age response header" pending=pending_has_url <| Test.with_retries <|
            group_builder.specify "Should not cache if the request fails" pending=pending_has_url <| Test.with_retries <|
            group_builder.specify "Should work with secrets in the URI" pending=pending_has_url <| Test.with_retries <|
            group_builder.specify "Should work with secrets in the headers" pending=pending_has_url <| Test.with_retries <|
            group_builder.specify "Cache state should be consistent" pending=pending_has_url <| Test.with_retries <|
                # Check that map matches files on disk
